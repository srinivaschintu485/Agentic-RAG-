{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z2kbg8h28LP7"
      },
      "outputs": [],
      "source": [
        "!pip install pandas langchain langchain-community sentence-transformers faiss-cpu \"transformers[agents]\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers[agents]\n"
      ],
      "metadata": {
        "id": "HfrVjX3W8seZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install \"git+https://github.com/huggingface/transformers.git#egg=transformers[agents]\""
      ],
      "metadata": {
        "id": "UuXPhnXs8U-7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip uninstall transformers -y\n",
        "!pip install transformers"
      ],
      "metadata": {
        "id": "xrvtyaNzvOr7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "CiFL6C9GzpJP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install transformers==4.31.0\n"
      ],
      "metadata": {
        "id": "d9zNEFUuvc6R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import transformers\n",
        "print(transformers.__version__)"
      ],
      "metadata": {
        "id": "svEGnMNJu8uL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.tools import HfAgent"
      ],
      "metadata": {
        "id": "9OWptGlMv8Uf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.tools import Tool\n",
        "from transformers import HfAgent\n"
      ],
      "metadata": {
        "id": "oCHRexqbwUCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary modules\n",
        "import pandas as pd\n",
        "import datasets\n",
        "from transformers import AutoTokenizer\n",
        "from langchain.docstore.document import Document\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.vectorstores import FAISS\n",
        "from langchain_community.embeddings import HuggingFaceEmbeddings\n",
        "from langchain_community.vectorstores.utils import DistanceStrategy\n",
        "from tqdm import tqdm\n",
        "#from transformers.agents import Tool, ReactJsonAgent\n",
        "from huggingface_hub import InferenceClient\n",
        "from transformers.tools import HfAgent\n",
        "import logging\n",
        "\n",
        "# Set up logging\n",
        "logging.basicConfig(level=logging.INFO)\n",
        "logger = logging.getLogger(__name__)"
      ],
      "metadata": {
        "id": "a_2XSwd28cDU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load the knowledge base\n",
        "knowledge_base = datasets.load_dataset(\"m-ric/huggingface_doc\", split=\"train\")"
      ],
      "metadata": {
        "id": "IcSFSqvl8m4j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "knowledge_base"
      ],
      "metadata": {
        "id": "npvW9FM_8omd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert dataset to Document objects\n",
        "source_docs = [\n",
        "    Document(page_content=doc[\"text\"], metadata={\"source\": doc[\"source\"].split(\"/\")[1]})\n",
        "    for doc in knowledge_base\n",
        "]\n",
        "\n",
        "logger.info(f\"Loaded {len(source_docs)} documents from the knowledge base\")"
      ],
      "metadata": {
        "id": "SHcQok5G9nWI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "source_docs"
      ],
      "metadata": {
        "id": "gizBUwpy9wUk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the text splitter\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"thenlper/gte-small\")\n",
        "text_splitter = RecursiveCharacterTextSplitter.from_huggingface_tokenizer(\n",
        "    tokenizer,\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    add_start_index=True,\n",
        "    strip_whitespace=True,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \", \"\"],\n",
        ")"
      ],
      "metadata": {
        "id": "TljRa80386t1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split documents and remove duplicates\n",
        "logger.info(\"Splitting documents...\")\n",
        "docs_processed = []\n",
        "unique_texts = {}\n",
        "for doc in tqdm(source_docs):\n",
        "    new_docs = text_splitter.split_documents([doc])\n",
        "    for new_doc in new_docs:\n",
        "        if new_doc.page_content not in unique_texts:\n",
        "            unique_texts[new_doc.page_content] = True\n",
        "            docs_processed.append(new_doc)\n",
        "\n",
        "logger.info(f\"Processed {len(docs_processed)} unique document chunks\")"
      ],
      "metadata": {
        "id": "5edsGWIA88ZY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers"
      ],
      "metadata": {
        "id": "QqtehokexNxl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install --upgrade transformers sentence-transformers"
      ],
      "metadata": {
        "id": "aksjkXQCy1Oj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall transformers sentence-transformers -y\n",
        "!pip install transformers sentence-transformers"
      ],
      "metadata": {
        "id": "wz5LHJPTzcRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install sentence-transformers==2.2.2\n"
      ],
      "metadata": {
        "id": "sqhZvaW6130l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip uninstall huggingface_hub\n",
        "!pip install huggingface_hub==0.25.2\n"
      ],
      "metadata": {
        "id": "lIcZtgA922BD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the embedding model\n",
        "logger.info(\"Initializing embedding model...\")\n",
        "embedding_model = HuggingFaceEmbeddings(model_name=\"thenlper/gte-small\")\n",
        "\n",
        "# Create the vector database\n",
        "logger.info(\"Creating vector database...\")\n",
        "vectordb = FAISS.from_documents(\n",
        "    documents=docs_processed,\n",
        "    embedding=embedding_model,\n",
        "    distance_strategy=DistanceStrategy.COSINE,\n",
        ")\n",
        "\n",
        "logger.info(\"Vector database created successfully\")"
      ],
      "metadata": {
        "id": "94pcBGUc9HSZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Building the RetrieverTool\n"
      ],
      "metadata": {
        "id": "yHI2fu6n9Pqc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RetrieverTool(Tool):\n",
        "    name = \"retriever\"\n",
        "    description = \"Using semantic similarity, retrieves some documents from the knowledge base that have the closest embeddings to the input query.\"\n",
        "    inputs = {\n",
        "        \"query\": {\n",
        "            \"type\": \"text\",\n",
        "            \"description\": \"The query to perform. This should be semantically close to your target documents. Use the affirmative form rather than a question.\",\n",
        "        }\n",
        "    }\n",
        "    output_type = \"text\"\n",
        "\n",
        "    def __init__(self, vectordb, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.vectordb = vectordb\n",
        "\n",
        "    def forward(self, query: str) -> str:\n",
        "        assert isinstance(query, str), \"Your search query must be a string\"\n",
        "\n",
        "        docs = self.vectordb.similarity_search(\n",
        "            query,\n",
        "            k=7,\n",
        "        )\n",
        "\n",
        "        return \"\\nRetrieved documents:\\n\" + \"\".join(\n",
        "            [f\"===== Document {str(i)} =====\\n\" + doc.page_content for i, doc in enumerate(docs)]\n",
        "        )\n",
        "\n",
        "# Create an instance of the RetrieverTool\n",
        "retriever_tool = RetrieverTool(vectordb)"
      ],
      "metadata": {
        "id": "TK6kAoKd9Qem"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "retriever_tool"
      ],
      "metadata": {
        "id": "aXnGxXDW92wT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login"
      ],
      "metadata": {
        "id": "xmdfVtfN-DXm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "notebook_login()"
      ],
      "metadata": {
        "id": "P5eGgXjY-EWW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import HfEngine\n"
      ],
      "metadata": {
        "id": "ltRqF8aG7EYI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers.agents import HfApiEngine"
      ],
      "metadata": {
        "id": "UrAAfXgy74D7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import HfApi"
      ],
      "metadata": {
        "id": "9o4uEh4D8NPn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from transformers import HfApiEngine\n"
      ],
      "metadata": {
        "id": "UBC5HFNy7jWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Initialize the language model engine\n",
        "llm_engine = HfApi(\"meta-llama/Meta-Llama-3-8B-Instruct\")"
      ],
      "metadata": {
        "id": "p0NgWMVK-HGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip install git+https://github.com/huggingface/transformers.git#egg=transformers\n"
      ],
      "metadata": {
        "id": "ynUo8y4O-syN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pip show transformers\n"
      ],
      "metadata": {
        "id": "dLZ5puzv8oZh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### IF YOU WANT TO USE OPENAI"
      ],
      "metadata": {
        "id": "n6c_COxBuQl2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from openai import OpenAI\n",
        "\n",
        "from typing import List, Dict\n",
        "from transformers.agents.llm_engine import MessageRole, get_clean_message_list\n",
        "from huggingface_hub import InferenceClient\n",
        "\n",
        "openai_role_conversions = {\n",
        "    MessageRole.TOOL_RESPONSE: MessageRole.USER,\n",
        "}\n",
        "\n",
        "\n",
        "class OpenAIEngine:\n",
        "    def __init__(self, model_name=\"gpt-4o\"):\n",
        "        self.model_name = model_name\n",
        "        self.client = OpenAI(\n",
        "            api_key=\"YOUR-API-KEY\"#os.getenv(\"OPENAI_API_KEY\"),\n",
        "        )\n",
        "\n",
        "    def __call__(self, messages, stop_sequences=[]):\n",
        "        messages = get_clean_message_list(messages, role_conversions=openai_role_conversions)\n",
        "\n",
        "        response = self.client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=messages,\n",
        "            stop=stop_sequences,\n",
        "            temperature=0.5,\n",
        "        )\n",
        "        return response.choices[0].message.content"
      ],
      "metadata": {
        "id": "F3kuN8meuPIn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "llm_engine = OpenAIEngine()"
      ],
      "metadata": {
        "id": "Bd9BfMsPuYBb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create the agent\n",
        "agent = ReactJsonAgent(tools=[retriever_tool], llm_engine=llm_engine, max_iterations=4, verbose=2)"
      ],
      "metadata": {
        "id": "O6gGoOmu-Nly"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to run the agent\n",
        "def run_agentic_rag(question: str) -> str:\n",
        "    enhanced_question = f\"\"\"Using the information contained in your knowledge base, which you can access with the 'retriever' tool,\n",
        "give a comprehensive answer to the question below.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "If you cannot find information, do not give up and try calling your retriever again with different arguments!\n",
        "Make sure to have covered the question completely by calling the retriever tool several times with semantically different queries.\n",
        "Your queries should not be questions but affirmative form sentences: e.g. rather than \"How do I load a model from the Hub in bf16?\", query should be \"load a model from the Hub bf16 weights\".\n",
        "\n",
        "Question:\n",
        "{question}\"\"\"\n",
        "\n",
        "    return agent.run(enhanced_question)\n"
      ],
      "metadata": {
        "id": "f7O5Swvn-Oh7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage\n",
        "question = \"How can I push a model to the Hub?\"\n",
        "answer = run_agentic_rag(question)\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "metadata": {
        "id": "EaTvuVuh-RLL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Comparing Agentic RAG to standard RAG"
      ],
      "metadata": {
        "id": "qYCULF8E-Ydm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standard RAG function\n",
        "def run_standard_rag(question: str) -> str:\n",
        "    context = retriever_tool(question)\n",
        "\n",
        "    prompt = f\"\"\"Given the question and supporting documents below, give a comprehensive answer to the question.\n",
        "Respond only to the question asked, response should be concise and relevant to the question.\n",
        "Provide the number of the source document when relevant.\n",
        "\n",
        "Question:\n",
        "{question}\n",
        "\n",
        "{context}\n",
        "\"\"\"\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "\n",
        "    reader_llm = InferenceClient(\"meta-llama/Meta-Llama-3-8B-Instruct\")\n",
        "\n",
        "    return reader_llm.chat_completion(messages).choices[0].message.content"
      ],
      "metadata": {
        "id": "soAy1y1m-UrU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Compare Agentic RAG and Standard RAG\n",
        "question = \"How can I push a model to the Hub?\"\n",
        "agentic_answer = run_agentic_rag(question)"
      ],
      "metadata": {
        "id": "YoMyLczM-fFD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "standard_answer = run_standard_rag(question)"
      ],
      "metadata": {
        "id": "UvSLvpkR-f_Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Agentic RAG Answer:\")\n",
        "print(agentic_answer)\n"
      ],
      "metadata": {
        "id": "gbwqh-be-lmA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"\\nStandard RAG Answer:\")\n",
        "print(standard_answer)"
      ],
      "metadata": {
        "id": "QJAKWGPv-mQ9"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}